{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import ImageOps, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './data/benign-malignant/train/'\n",
    "TEST_DIR = './data/benign-malignant/test/'\n",
    "\n",
    "CLASS = ['benign', 'malignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train 4 more models\n",
    "\n",
    "#Pending\n",
    "# 1. For melanoma and non-melanoma without any pre-processing  -> Data Required\n",
    "# 2. For melanoma and non-melanoma with sharpening -> Data required\n",
    "# 3. For benign and malignant with age and gender -> Data Found cleaning is required\n",
    "# 4. For melanoma and non-melanoma without age and gender -> Data required\n",
    "# 5. For melanoma and non-melanoma with \"normalization\" -> Data required\n",
    "\n",
    "\n",
    "# 6. For benign and malignant with \"normalization\" -> Data Found Preprocessing is required\n",
    "# 7. For bengin and malignant without preprocessing -> Data found -> Done\n",
    "# 8. For benign and malignant with sharpening -> Data Found -> Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2937 images belonging to 2 classes.\n",
      "Found 360 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "327/327 [==============================] - 951s 3s/step - loss: 2.3331 - accuracy: 0.6902 - val_loss: 0.7121 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "327/327 [==============================] - 929s 3s/step - loss: 1.0744 - accuracy: 0.6823 - val_loss: 0.7030 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "327/327 [==============================] - 897s 3s/step - loss: 1.6647 - accuracy: 0.6881 - val_loss: 1.0007 - val_accuracy: 0.8111\n",
      "Epoch 4/20\n",
      "327/327 [==============================] - 867s 3s/step - loss: 0.9809 - accuracy: 0.7205 - val_loss: 1.1104 - val_accuracy: 0.4778\n",
      "Epoch 5/20\n",
      "327/327 [==============================] - 806s 2s/step - loss: 0.6073 - accuracy: 0.7637 - val_loss: 0.5338 - val_accuracy: 0.6944\n",
      "Epoch 6/20\n",
      "327/327 [==============================] - 818s 3s/step - loss: 0.5893 - accuracy: 0.7681 - val_loss: 0.9954 - val_accuracy: 0.4611\n",
      "Epoch 7/20\n",
      "327/327 [==============================] - 843s 3s/step - loss: 0.5748 - accuracy: 0.7566 - val_loss: 1.7558 - val_accuracy: 0.3083\n",
      "Epoch 8/20\n",
      "327/327 [==============================] - 852s 3s/step - loss: 0.5434 - accuracy: 0.7709 - val_loss: 0.2619 - val_accuracy: 0.8139\n",
      "Epoch 9/20\n",
      "327/327 [==============================] - 799s 2s/step - loss: 0.6337 - accuracy: 0.7613 - val_loss: 0.9583 - val_accuracy: 0.5333\n",
      "Epoch 10/20\n",
      "327/327 [==============================] - 826s 3s/step - loss: 0.6526 - accuracy: 0.7521 - val_loss: 1.9242 - val_accuracy: 0.4556\n",
      "Epoch 11/20\n",
      "327/327 [==============================] - 785s 2s/step - loss: 0.6521 - accuracy: 0.7623 - val_loss: 0.6339 - val_accuracy: 0.6722\n",
      "Epoch 12/20\n",
      "327/327 [==============================] - 790s 2s/step - loss: 0.6151 - accuracy: 0.7719 - val_loss: 0.3398 - val_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "327/327 [==============================] - 810s 2s/step - loss: 0.6083 - accuracy: 0.7617 - val_loss: 0.3065 - val_accuracy: 0.7861\n",
      "Epoch 14/20\n",
      "327/327 [==============================] - 795s 2s/step - loss: 0.6318 - accuracy: 0.7647 - val_loss: 0.8009 - val_accuracy: 0.5389\n",
      "Epoch 15/20\n",
      "327/327 [==============================] - 825s 3s/step - loss: 0.5936 - accuracy: 0.7586 - val_loss: 0.4347 - val_accuracy: 0.7167\n",
      "Epoch 16/20\n",
      "327/327 [==============================] - 837s 3s/step - loss: 0.7451 - accuracy: 0.7562 - val_loss: 133.9190 - val_accuracy: 0.0306\n",
      "Epoch 17/20\n",
      "327/327 [==============================] - 861s 3s/step - loss: 0.9104 - accuracy: 0.7252 - val_loss: 937.2018 - val_accuracy: 0.1306\n",
      "Epoch 18/20\n",
      "327/327 [==============================] - 835s 3s/step - loss: 0.7007 - accuracy: 0.7157 - val_loss: 1.7198 - val_accuracy: 0.6694\n",
      "Epoch 19/20\n",
      "327/327 [==============================] - 859s 3s/step - loss: 0.6267 - accuracy: 0.7521 - val_loss: 0.5087 - val_accuracy: 0.7361\n",
      "Epoch 20/20\n",
      "327/327 [==============================] - 876s 3s/step - loss: 0.5954 - accuracy: 0.7518 - val_loss: 0.6937 - val_accuracy: 0.5889\n"
     ]
    }
   ],
   "source": [
    "# Normalizing images\n",
    "\n",
    "# Model with processing\n",
    "PRE_PROCESS = './data/benign-malignant/normalization/'\n",
    "\n",
    "# b_train = os.listdir(TRAIN_DIR + 'benign/')\n",
    "# b_test = os.listdir(TEST_DIR + 'benign/')\n",
    "\n",
    "# m_train = os.listdir(TRAIN_DIR + 'malignant/')\n",
    "# m_test = os.listdir(TEST_DIR + 'malignant/')\n",
    "\n",
    "# TRAIN_DIR = './data/benign-malignant/train/'\n",
    "# TEST_DIR = './data/benign-malignant/test/'\n",
    "\n",
    "#Pre-processing training directory (NORMALIZATION)\n",
    "#For benign\n",
    "# for i in range(len(b_train)):\n",
    "#     img = cv2.imread(TRAIN_DIR + 'benign/' + b_train[i])\n",
    "#     new_img = cv2.normalize(img, None, \n",
    "#                             alpha=0, beta=200, \n",
    "#                             norm_type=cv2.NORM_MINMAX)\n",
    "#     cv2.imwrite(PRE_PROCESS + 'train/benign/' + b_train[i], new_img)\n",
    "\n",
    "#For malignant\n",
    "# for i in range(len(m_train)):\n",
    "#     img = cv2.imread(TRAIN_DIR + 'malignant/' + m_train[i])\n",
    "#     new_img = cv2.normalize(img, None, \n",
    "#                             alpha=0, beta=200, \n",
    "#                             norm_type=cv2.NORM_MINMAX)\n",
    "#     cv2.imwrite(PRE_PROCESS + 'train/malignant/' + m_train[i], new_img)\n",
    "\n",
    "\n",
    "#Pre-processing validation directory\n",
    "#For benign\n",
    "# for i in range(len(b_test)):\n",
    "#     img = cv2.imread(TEST_DIR + 'benign/' + b_test[i])\n",
    "#     new_img = cv2.normalize(img, None, \n",
    "#                             alpha=0, beta=200, \n",
    "#                             norm_type=cv2.NORM_MINMAX)\n",
    "#     cv2.imwrite(PRE_PROCESS + 'test/benign/' + b_test[i], new_img)\n",
    "\n",
    "#For malignant\n",
    "# for i in range(len(m_test)):\n",
    "#     img = cv2.imread(TEST_DIR + 'malignant/' + m_test[i])\n",
    "#     new_img = cv2.normalize(img, None, \n",
    "#                             alpha=0, beta=200, \n",
    "#                             norm_type=cv2.NORM_MINMAX)\n",
    "#     cv2.imwrite(PRE_PROCESS + 'train/malignant/' + m_test[i], new_img)\n",
    "    \n",
    "\n",
    "generator = trainGenerator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "TRAIN_DIR = PRE_PROCESS + 'train/'\n",
    "TEST_DIR = PRE_PROCESS + 'test/'\n",
    "\n",
    "train = generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 9,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "val = generator.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "      train,\n",
    "      epochs=20,\n",
    "      validation_data=val\n",
    ")\n",
    "\n",
    "model.save('../models1/resnet/with-normalization.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2637 images belonging to 2 classes.\n",
      "Found 660 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "293/293 [==============================] - 764s 3s/step - loss: 2.2713 - accuracy: 0.6925 - val_loss: 0.6938 - val_accuracy: 0.4545\n",
      "Epoch 2/15\n",
      "293/293 [==============================] - 740s 3s/step - loss: 0.8923 - accuracy: 0.7144 - val_loss: 0.6934 - val_accuracy: 0.4545\n",
      "Epoch 3/15\n",
      "293/293 [==============================] - 740s 3s/step - loss: 0.8665 - accuracy: 0.7239 - val_loss: 0.7565 - val_accuracy: 0.3000\n",
      "Epoch 4/15\n",
      "293/293 [==============================] - 740s 3s/step - loss: 0.6551 - accuracy: 0.7232 - val_loss: 0.7598 - val_accuracy: 0.7621\n",
      "Epoch 5/15\n",
      "293/293 [==============================] - 891s 3s/step - loss: 0.5988 - accuracy: 0.7425 - val_loss: 0.7617 - val_accuracy: 0.4955\n",
      "Epoch 6/15\n",
      "293/293 [==============================] - 996s 3s/step - loss: 0.5608 - accuracy: 0.7395 - val_loss: 1.2311 - val_accuracy: 0.7242\n",
      "Epoch 7/15\n",
      "293/293 [==============================] - 961s 3s/step - loss: 0.6761 - accuracy: 0.7368 - val_loss: 1.5201 - val_accuracy: 0.6788\n",
      "Epoch 8/15\n",
      "293/293 [==============================] - 833s 3s/step - loss: 0.5857 - accuracy: 0.7581 - val_loss: 0.7074 - val_accuracy: 0.6955\n",
      "Epoch 9/15\n",
      "293/293 [==============================] - 854s 3s/step - loss: 0.6345 - accuracy: 0.7315 - val_loss: 0.5481 - val_accuracy: 0.6545\n",
      "Epoch 10/15\n",
      "293/293 [==============================] - 856s 3s/step - loss: 0.6152 - accuracy: 0.7376 - val_loss: 0.8327 - val_accuracy: 0.7667\n",
      "Epoch 11/15\n",
      "293/293 [==============================] - 745s 3s/step - loss: 0.6350 - accuracy: 0.7198 - val_loss: 0.5697 - val_accuracy: 0.7697\n",
      "Epoch 12/15\n",
      "293/293 [==============================] - 718s 2s/step - loss: 0.6081 - accuracy: 0.7467 - val_loss: 0.7556 - val_accuracy: 0.7197\n",
      "Epoch 13/15\n",
      "293/293 [==============================] - 715s 2s/step - loss: 0.5532 - accuracy: 0.7486 - val_loss: 0.5235 - val_accuracy: 0.7727\n",
      "Epoch 14/15\n",
      "293/293 [==============================] - 712s 2s/step - loss: 0.5183 - accuracy: 0.7630 - val_loss: 1.3396 - val_accuracy: 0.6561\n",
      "Epoch 15/15\n",
      "293/293 [==============================] - 715s 2s/step - loss: 0.5578 - accuracy: 0.7402 - val_loss: 1.0391 - val_accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = './data/benign-malignant/train/'\n",
    "TEST_DIR = './data/benign-malignant/test/'\n",
    "\n",
    "generator = trainGenerator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train = generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 9,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "val = generator.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "      train,\n",
    "      epochs=15,\n",
    "      validation_data=val\n",
    ")\n",
    "\n",
    "model.save('../models1/resent/without-preprocessing1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3297 images belonging to 2 classes.\n",
      "Found 3297 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "367/367 [==============================] - 1066s 3s/step - loss: 1.5185 - accuracy: 0.8611 - val_loss: 0.6645 - val_accuracy: 0.8908\n",
      "Epoch 2/15\n",
      "367/367 [==============================] - 1032s 3s/step - loss: 0.8711 - accuracy: 0.8759 - val_loss: 6.7971 - val_accuracy: 0.8908\n",
      "Epoch 3/15\n",
      "367/367 [==============================] - 1037s 3s/step - loss: 0.6105 - accuracy: 0.8784 - val_loss: 0.3891 - val_accuracy: 0.8908\n",
      "Epoch 4/15\n",
      "367/367 [==============================] - 1056s 3s/step - loss: 0.5530 - accuracy: 0.8805 - val_loss: 0.4608 - val_accuracy: 0.8908\n",
      "Epoch 5/15\n",
      "367/367 [==============================] - 1048s 3s/step - loss: 0.4828 - accuracy: 0.8820 - val_loss: 0.4289 - val_accuracy: 0.8908\n",
      "Epoch 6/15\n",
      "367/367 [==============================] - 1035s 3s/step - loss: 0.4635 - accuracy: 0.8832 - val_loss: 0.6390 - val_accuracy: 0.8908\n",
      "Epoch 7/15\n",
      "367/367 [==============================] - 1032s 3s/step - loss: 0.4675 - accuracy: 0.8820 - val_loss: 0.5614 - val_accuracy: 0.8908\n",
      "Epoch 8/15\n",
      "367/367 [==============================] - 1068s 3s/step - loss: 0.4499 - accuracy: 0.8844 - val_loss: 0.3934 - val_accuracy: 0.8535\n",
      "Epoch 9/15\n",
      "367/367 [==============================] - 1049s 3s/step - loss: 0.4686 - accuracy: 0.8829 - val_loss: 0.3486 - val_accuracy: 0.8908\n",
      "Epoch 10/15\n",
      "367/367 [==============================] - 1045s 3s/step - loss: 0.4274 - accuracy: 0.8850 - val_loss: 1.5388 - val_accuracy: 0.8908\n",
      "Epoch 11/15\n",
      "367/367 [==============================] - 1361s 4s/step - loss: 0.4652 - accuracy: 0.8841 - val_loss: 0.4413 - val_accuracy: 0.8908\n",
      "Epoch 12/15\n",
      "367/367 [==============================] - 1314s 4s/step - loss: 0.4663 - accuracy: 0.8841 - val_loss: 1.4691 - val_accuracy: 0.7880\n",
      "Epoch 13/15\n",
      "367/367 [==============================] - 1169s 3s/step - loss: 0.4431 - accuracy: 0.8844 - val_loss: 0.4595 - val_accuracy: 0.8908\n",
      "Epoch 14/15\n",
      "367/367 [==============================] - 1063s 3s/step - loss: 0.4430 - accuracy: 0.8838 - val_loss: 0.3772 - val_accuracy: 0.8908\n",
      "Epoch 15/15\n",
      "367/367 [==============================] - 1052s 3s/step - loss: 0.3779 - accuracy: 0.8884 - val_loss: 0.3443 - val_accuracy: 0.8872\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = './data/benign-malignant/sharpened/'\n",
    "TEST_DIR = './data/benign-malignant/sharpened/'\n",
    "\n",
    "generator = trainGenerator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train = generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 9,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "val = generator.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "      train,\n",
    "      epochs=15,\n",
    "      validation_data=val\n",
    ")\n",
    "\n",
    "model.save('../models1/resent/with-sharpening.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3297 images belonging to 2 classes.\n",
      "Found 3297 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "367/367 [==============================] - 255s 694ms/step - loss: 0.4166 - accuracy: 0.8890 - val_loss: 0.3479 - val_accuracy: 0.8908\n",
      "Epoch 2/15\n",
      "367/367 [==============================] - 253s 689ms/step - loss: 0.3703 - accuracy: 0.8908 - val_loss: 0.4763 - val_accuracy: 0.8908\n",
      "Epoch 3/15\n",
      "367/367 [==============================] - 234s 637ms/step - loss: 0.3562 - accuracy: 0.8908 - val_loss: 0.3426 - val_accuracy: 0.8908\n",
      "Epoch 4/15\n",
      "367/367 [==============================] - 223s 607ms/step - loss: 0.3837 - accuracy: 0.8905 - val_loss: 0.3463 - val_accuracy: 0.8908\n",
      "Epoch 5/15\n",
      "367/367 [==============================] - 222s 604ms/step - loss: 0.3916 - accuracy: 0.8908 - val_loss: 0.3451 - val_accuracy: 0.8908\n",
      "Epoch 6/15\n",
      "367/367 [==============================] - 222s 604ms/step - loss: 0.3513 - accuracy: 0.8908 - val_loss: 0.3475 - val_accuracy: 0.8908\n",
      "Epoch 7/15\n",
      "367/367 [==============================] - 224s 610ms/step - loss: 0.3491 - accuracy: 0.8908 - val_loss: 0.3489 - val_accuracy: 0.8905\n",
      "Epoch 8/15\n",
      "367/367 [==============================] - 223s 607ms/step - loss: 0.3778 - accuracy: 0.8902 - val_loss: 0.3434 - val_accuracy: 0.8908\n",
      "Epoch 9/15\n",
      "367/367 [==============================] - 224s 611ms/step - loss: 0.3487 - accuracy: 0.8905 - val_loss: 0.3436 - val_accuracy: 0.8908\n",
      "Epoch 10/15\n",
      "367/367 [==============================] - 223s 608ms/step - loss: 0.3496 - accuracy: 0.8908 - val_loss: 0.3463 - val_accuracy: 0.8908\n",
      "Epoch 11/15\n",
      "367/367 [==============================] - 224s 610ms/step - loss: 0.3466 - accuracy: 0.8908 - val_loss: 0.3485 - val_accuracy: 0.8908\n",
      "Epoch 12/15\n",
      "367/367 [==============================] - 225s 613ms/step - loss: 0.3500 - accuracy: 0.8905 - val_loss: 0.3425 - val_accuracy: 0.8908\n",
      "Epoch 13/15\n",
      "367/367 [==============================] - 223s 606ms/step - loss: 0.3432 - accuracy: 0.8908 - val_loss: 0.3547 - val_accuracy: 0.8908\n",
      "Epoch 14/15\n",
      "367/367 [==============================] - 220s 598ms/step - loss: 0.3445 - accuracy: 0.8908 - val_loss: 0.3436 - val_accuracy: 0.8908\n",
      "Epoch 15/15\n",
      "367/367 [==============================] - 226s 616ms/step - loss: 0.3458 - accuracy: 0.8908 - val_loss: 0.3443 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = './data/benign-malignant/normalization/'\n",
    "TEST_DIR = './data/benign-malignant/normalization/'\n",
    "\n",
    "generator = trainGenerator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train = generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 9,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "val = generator.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (225, 225, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "      train,\n",
    "      epochs=15,\n",
    "      validation_data=val\n",
    ")\n",
    "\n",
    "model.save('../models1/resnet/with-normalization.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c081257499a92776a7ff5343ee4d85420a7950a6ae97b0cb2aee7a7ddd41b7f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
